<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
  <title>Project-2 </title>
  
  <!-- 
    - favicon
  -->
  <link rel="shortcut icon" href="./favicon.svg" type="image/svg+xml">

  <!-- 
    - custom css link
  -->
  <link rel="stylesheet" href="./assets/css/style.css">

  <!-- 
    - google font link
  -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Barlow:wght@600;700&family=Open+Sans:wght@400;500;700&family=Poppins:wght@400;600&display=swap"
    rel="stylesheet">
</head>

<body id="top">

  <!-- 
    - #HEADER
  -->

  <header class="header" data-header>
    <div class="container">

      <a href="#">
        <h1 >MY PROJECTS </h1>
      </a>

      <button class="nav-toggle-btn" aria-label="Toggle Menu" data-nav-toggle-btn>
        <ion-icon name="menu-outline" class="menu-icon"></ion-icon>
        <ion-icon name="close-outline" class="close-icon"></ion-icon>
      </button>

      <nav class="navbar container">
        <ul class="navbar-list">

          <li>
            <a href="index.html" class="navbar-link" data-nav-link>HOME</a>
          </li>

          <li>
            <a href="#about" class="navbar-link" data-nav-link>DESCRIPTION</a>
          </li>

          <li>
            <a href="#portfolio" class="navbar-link" data-nav-link>FEATURES</a>
          </li>

          <li>
            <a href="#blog" class="navbar-link" data-nav-link>SOURCE CODE</a>
          </li>

          <li>
            <a href="#" class="btn btn-primary">PORTFOLIO</a>
          </li>

        </ul>
      </nav>

    </div>
  </header>





  <main>
    <article>

      <!-- 
        - #HERO
      -->

      <section class="hero" id="home">
        <div class="container">

          <div class="hero-banner">

            <img src="./assets/images/ai-human.jpg"  loading="lazy" alt="hero-banner.jpg"
              class="img-cover">

            <div class="elem elem-2">
              <p class="elem-title">AI</p>

              <p class="elem-text">Based Technology</p>
            </div>

          </div>

          <div class="hero-content">

            <h2 class="hero-title">
              <span> TITLE </span>
              <strong>Volume & Brightness Control using Hand Gestures  </strong> 
            </h2>

            <p class="hero-text">
                Developed a Python-AI technology that detects hand gestures and performs actions accordingly.I have developed an AI-based system that allows users to control the volume and brightness of their devices through intuitive hand gestures. Leveraging advanced computer vision and machine learning technologies, our solution provides a hands-free and seamless user experience.
            </p>

            

          </div>

        </div>
      </section>





      <!-- 
        - #ABOUT
      -->

      <section class="section about" id="about">
        <div class="container">

          <figure class="about-banner">

            <img src="./assets/images/robothand.jpg" width="800" height="800" loading="lazy" alt="hero-banner.jpg"
              class="img-cover">

            
          </figure>

          <div class="about-content">

            <p class="section-subtitle">PROJECT DESCRIPTION</p>

            <br>

            <p class="section-text">The system is trained to recognize a variety of hand gestures accurately.
                Different gestures are mapped to specific commands, such as adjusting volume or brightness.
                
                
                By making simple hand movements, users can increase or decrease the volume of their devices.
                The system ensures precise control, responding to subtle gestures for a seamless user experience.
            
                
                Users can effortlessly control the brightness of their screens through natural hand gestures.
                The system adapts to different ambient lighting conditions, providing optimal visibility
            </p>

            
            <h2 class="h2 section-title">Click the below button to view Features</h2>

            <a href="#portfolio" class="btn btn-primary blue">FEATURES</a>

          </div>

        </div>
      </section>





      <!-- 
        - #PORTFOLIO
      -->

      <section class="section portfolio" id="portfolio">
        <div class="container">

          <p class="section-subtitle">FEATURES</p>

          <h2 class="h2 section-title">Some of the Key Features </h2>


          <section class="section about" id="project">
            <div class="container">
    
              <figure class="about-banner">
    
                <img src="./assets/images/handgesture.webp" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                  class="img-cover">
    
                
              </figure>
    
              <div class="about-content">
    
                
                <p class="section-subtitle">Gesture Recognition:</p>
                <p class="section-text">The system is trained to recognize a variety of hand gestures accurately.
                  Different gestures are mapped to specific commands, such as adjusting volume or brightness.
                <p class="section-subtitle">Volume Control:</p>
                <p class="section-text">By making simple hand movements, users can increase or decrease the volume of their devices.
                  The system ensures precise control, responding to subtle gestures for a seamless user experience.
                  The system adapts to different ambient lighting conditions, providing optimal visibility.
                </p>
              </div>
              <figure class="about-banner">
      
                  <img src="./assets/images/hand.jpg" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                    class="img-cover">
                   </figure>
              <div class="about-content">   
                <p class="section-subtitle">Brightness Adjustment:</p>
                <p class="section-text">Users can effortlessly control the brightness of their screens through natural hand gestures.
                  The system adapts to different ambient lighting conditions, providing optimal visibility.
                </p>
                <p class="section-subtitle">Computer Vision Technology:</p>
                <p class="section-text">he project utilizes computer vision algorithms to analyze and interpret hand movements in real-time.
                  OpenCV (Open Source Computer Vision Library) and other advanced image processing techniques enhance accuracy.
                </p>
                <p class="section-subtitle">Machine Learning Integration:</p>
                <p class="section-text">Machine learning models are employed to continuously improve gesture recognition over time.
                  The system adapts to individual user preferences, making it a personalized and user-friendly experience.</p>
                </div>
         
                <figure class="about-banner">
      
                  <img src="./assets/images/3d-robot-hand-background-ai-technology-side-view.jpg" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                    class="img-cover">
                   </figure>

                   <div class="about-content">   
                    <p class="section-subtitle">Compatibility:</p>
                    <p class="section-text">Our solution is designed to be platform-independent and compatible with various devices, including laptops, desktops, and smart TVs.

                    </p>     
                    <p class="section-subtitle">Real-time Feedback:</p>
                    <p class="section-text">Users receive real-time visual and audio feedback as they perform gestures, ensuring a seamless and responsive interaction.
                      </p>

                    </div>

                    <figure class="about-banner">
      
                      <img src="./assets/images/gesture-recognition.jpg" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                        class="img-cover">
                       </figure>
                  <div class="about-content">   
                    <p class="section-subtitle">WORKING PROCESS</p><br>
                    <p class="section-text">In summary, the working process of a Volume and Brightness control system using hand gestures involves capturing and interpreting hand movements through a sensor, processing this data with a gesture recognition algorithm, translating gestures into control commands, and adjusting the output devices accordingly while providing feedback to the user. Optional features such as voice commands and user customization further enhance the overall functionality and user experience.</p>
                    </div>
                  </section>

                  <center>
                     
                      <p class="section-subtitle">DETAILED PROCESS</p><br>
                       <br>
                      <ol>
                        <p class="section-subtitle">1. Hardware Setup:</p><br>
                        <p class="section-text" >The first step involves setting up the necessary hardware components. This typically includes a camera or sensor to capture hand gestures, a microphone for voice commands (optional), and speakers or a display to reflect changes in volume and brightness. Additionally, a microcontroller or a computer is required to process the input data and control the output devices.
                        <br>
                        <p class="section-subtitle" >2. Gesture Recognition Algorithm:</p><br>
                        <p class="section-text" >The core of the system is the gesture recognition algorithm. This software component analyzes the input data from the camera or sensor to identify specific hand gestures. Common gestures for volume control may include swiping up or down, while brightness control gestures might involve swiping left or right. Machine learning techniques, such as computer vision algorithms or neural networks, can be employed to train the system to recognize these gestures accurately.
                          <br>
                          <p class="section-subtitle" >3. Data Processing:</p><br>
                        <p class="section-text" >Once the gestures are recognized, the system processes this information to determine the corresponding control commands. For volume control, the algorithm may translate a swipe up gesture into an increase in volume and a swipe down gesture into a decrease. Similarly, for brightness control, left and right swipes may correspond to decreasing or increasing brightness levels<br>
                    
                          <p class="section-subtitle">4. Communication with Output Devices:</p><br>
                          <p class="section-text" >
                            The system then communicates with the output devices, such as speakers or a display, to implement the desired changes. For volume control, it may adjust the audio output level, while for brightness control, it may modify the display settings. The communication can be achieved through standard protocols like HDMI-CEC or via direct control if integrated into the same device.
                            <br>
                            <p class="section-subtitle">5. Gesture Recognition Algorithm:</p><br>
                          <p class="section-text" >
                            A gesture recognition algorithm interprets the captured data to identify and classify the gestures performed by the user. Machine learning techniques, such as computer vision algorithms or neural networks, are often employed to train the system to recognize different hand movements accurately.
                        <br>
                         </ol>
                         

                    </center>
                    <section class="section blog" id="blog">
                    <p class="section-subtitle">SOURCE CODE</p>

                    <h2 class="h2 section-title">The Source code will be provided in My GITHUB account.</h2>
          
                    <center>
                      <a href="https://github.com/chandhru02" class="btn btn-primary blue">GITHUB</a>
                    </center>
</section>