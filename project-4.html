<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
  <title>Project-4 </title>
  
  <!-- 
    - favicon
  -->
  <link rel="shortcut icon" href="./favicon.svg" type="image/svg+xml">

  <!-- 
    - custom css link
  -->
  <link rel="stylesheet" href="./assets/css/style.css">

  <!-- 
    - google font link
  -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Barlow:wght@600;700&family=Open+Sans:wght@400;500;700&family=Poppins:wght@400;600&display=swap"
    rel="stylesheet">
</head>

<body id="top">

  <!-- 
    - #HEADER
  -->

  <header class="header" data-header>
    <div class="container">

      <a href="#">
        <h1 >MY PROJECTS </h1>
      </a>

      <button class="nav-toggle-btn" aria-label="Toggle Menu" data-nav-toggle-btn>
        <ion-icon name="menu-outline" class="menu-icon"></ion-icon>
        <ion-icon name="close-outline" class="close-icon"></ion-icon>
      </button>

      <nav class="navbar container">
        <ul class="navbar-list">

          <li>
            <a href="index.html" class="navbar-link" data-nav-link>HOME</a>
          </li>

          <li>
            <a href="#about" class="navbar-link" data-nav-link>DESCRIPTION</a>
          </li>

          <li>
            <a href="#portfolio" class="navbar-link" data-nav-link>FEATURES</a>
          </li>

          <li>
            <a href="#blog" class="navbar-link" data-nav-link>SOURCE CODE</a>
          </li>

          <li>
            <a href="#" class="btn btn-primary">PORTFOLIO</a>
          </li>

        </ul>
      </nav>

    </div>
  </header>





  <main>
    <article>

      <!-- 
        - #HERO
      -->

      <section class="hero" id="home">
        <div class="container">

          <div class="hero-banner">

            <img src="./assets/images/eye.avif"  loading="lazy" alt="hero-banner.jpg"
              class="img-cover">

            <div class="elem elem-2">
              <p class="elem-title">AI</p>

              <p class="elem-text">Based Technology</p>
            </div>

          </div>

          <div class="hero-content">

            <h2 class="hero-title">
              <span> TITLE </span>
              <strong>AI Virtual Mouse using Eye Gesture Controller</strong> 
            </h2>

            <p class="hero-text">
                Designed an AI-driven virtual mouse using eye gestures to provide an alternative input method for computers.It presents a novel idea to control computer mouse cursor movement with human eyes. It controls mouse-moving by automatically affecting the position where eyesight focuses on, and simulates mouse-click by affecting blinking action. However, the proposed vision-based virtual interface controls system work on various eye movements such as eye blinking.Our system is mainly aimed for disabled peoples to have effective communication with computer.
            </p>

            

          </div>

        </div>
      </section>





      <!-- 
        - #ABOUT
      -->

      <section class="section about" id="about">
        <div class="container">

          <figure class="about-banner">

            <img src="./assets/images/ai1.jpg" width="800" height="800" loading="lazy" alt="hero-banner.jpg"
              class="img-cover">

            
          </figure>

          <div class="about-content">

            <p class="section-subtitle">PROJECT DESCRIPTION</p>

            <br>

            <p class="section-text">Traditionally, human computer interface uses mouse,keyboard as an input device. 
                This model presents hands free interface between computer and human for intuitive user experience.
                
                
                This technology is intended to replace the conventional computer screen pointing devices for the use of disabled persons.
                A system that presents a hands-free interface between human and computer by using the future technology AI.
            
                
                To perform these operations different algorithms like Haar Cascade algorithm, Dlib.
                This develops the futuristic prototype in current scenarios. 
            </p>

            
            <h2 class="h2 section-title">Click the below button to view Features</h2>

            <a href="#portfolio" class="btn btn-primary blue">FEATURES</a>

          </div>

        </div>
      </section>





      <!-- 
        - #PORTFOLIO
      -->

      <section class="section portfolio" id="portfolio">
        <div class="container">

          <p class="section-subtitle">FEATURES</p>

          <h2 class="h2 section-title">Some of the Key Features </h2>


          <section class="section about" id="project">
            <div class="container">
    
              <figure class="about-banner">
    
                <img src="./assets/images/ai2.jpg" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                  class="img-cover">
    
                
              </figure>
    
              <div class="about-content">
    
                
                <p class="section-subtitle">Gesture Recognition:</p>
                <p class="section-text">The system is trained to recognize a variety of eye gestures accurately.
                  Different gestures are mapped to specific commands, such as moving mouse and right click.

                <p class="section-subtitle">Mouse Operations:</p>
                <p class="section-text">By making simple eye movements, users can control various mouse movements of their devices.
                  The system ensures precise control, responding to subtle gestures for a seamless user experience.
                </p>
              </div>
              <figure class="about-banner">
      
                  <img src="./assets/images/ai3.webp" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                    class="img-cover">
                   </figure>
              <div class="about-content">   
                <p class="section-subtitle">Brightness Adjustment:</p>
                <p class="section-text">Users can effortlessly control the mouse movements through natural eye gestures.
                  The system adapts to different ambient lighting conditions, providing optimal visibility.
                </p>
                <p class="section-subtitle">Computer Vision Technology:</p>
                <p class="section-text">This project utilizes computer vision algorithms to analyze and interpret Eye movements in real-time.
                  OpenCV (Open Source Computer Vision Library) and other advanced image processing techniques enhance accuracy.
                </p>
                <p class="section-subtitle">Machine Learning Integration:</p>
                <p class="section-text">Machine learning models are employed to continuously improve gesture recognition over time.
                  The system adapts to individual user preferences, making it a personalized and user-friendly experience.</p>
                </div>
         
                <figure class="about-banner">
      
                  <img src="./assets/images/ai4.jpg" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                    class="img-cover">
                   </figure>

                   <div class="about-content">   
                    <p class="section-subtitle">Compatibility:</p>
                    <p class="section-text">Our solution is designed to be platform-independent and compatible with various devices, including laptops, desktops, and smart TVs.

                    </p>     
                    <p class="section-subtitle">Real-time Feedback:</p>
                    <p class="section-text">Users receive real-time visual and audio feedback as they perform gestures, ensuring a seamless and responsive interaction.
                      </p>

                    </div>

                    <figure class="about-banner">
      
                      <img src="./assets/images/ai5.jpg" width="1000" height="800" loading="lazy" alt="hero-banner.jpg"
                        class="img-cover">
                       </figure>
                  <div class="about-content">   
                    <p class="section-subtitle">WORKING PROCESS</p><br>
                    <p class="section-text">In summary, the working process of a AI Based Virtual Mouse using Eye gestures involves capturing and interpreting Eye movements through a sensor, processing this data with a gesture recognition algorithm, translating gestures into control commands, and adjusting the output devices accordingly while providing feedback to the user. Optional features such as voice commands and user customization further enhance the overall functionality and user experience.</p>
                    </div>
                  </section>

                  <center>
                     
                      <p class="section-subtitle">DETAILED PROCESS</p><br>
                       <br>
                      <ol>
                        <p class="section-subtitle">1. Hardware Setup:</p><br>
                        <p class="section-text" >The first step involves setting up the necessary hardware components. This typically includes a camera or sensor to capture eye gestures, a microphone for voice commands (optional), and speakers or a display to reflect changes in Mouse movements. Additionally, a microcontroller or a computer is required to process the input data and control the output devices.
                        <br>
                        <p class="section-subtitle" >2. Gesture Recognition Algorithm:</p><br>
                        <p class="section-text" >The core of the system is the gesture recognition algorithm. This software component analyzes the input data from the camera or sensor to identify specific eye gestures. Common gestures for Virtual Mouse may include Moving mouse cursor over the entire screen using naturak eye movements, while right mouse-click might involve closing right eye. Machine learning techniques, such as computer vision algorithms or neural networks, can be employed to train the system to recognize these gestures accurately.
                          <br>
                          <p class="section-subtitle" >3. Data Processing:</p><br>
                        <p class="section-text" >Once the gestures are recognized, the system processes this information to determine the corresponding control commands.<br>
                          <p class="section-subtitle">4. Communication with Output Devices:</p><br>
                          <p class="section-text" >
                            The system then communicates with the output devices, such as speakers or a display, to implement the desired changes. The communication can be achieved through standard protocols like HDMI-CEC or via direct control if integrated into the same device.<br>
                            <br>
                            <p class="section-subtitle">5. Gesture Recognition Algorithm:</p><br>
                          <p class="section-text" >
                            A gesture recognition algorithm interprets the captured data to identify and classify the gestures performed by the user. Machine learning techniques, such as computer vision algorithms or neural networks, are often employed to train the system to recognize different eye movements accurately.
                        <br>
                         </ol>
                         
                    </center>
                    <section class="section blog" id="blog">
                    <p class="section-subtitle">SOURCE CODE</p>

                    <h2 class="h2 section-title">The Source code will be provided in My GITHUB account.</h2>
          
                    <center>
                      <a href="https://github.com/chandhru02" class="btn btn-primary blue">GITHUB</a>
                    </center>
</section>